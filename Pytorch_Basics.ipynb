{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Basics",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicroprocessorX069/Pytorch-basics/blob/master/Pytorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnCrT4bxsW8F",
        "colab_type": "text"
      },
      "source": [
        "#Pytorch basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsk3v71ma28S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oD-8kSbbIhQ",
        "colab_type": "text"
      },
      "source": [
        "##Table of Contents\n",
        "\n",
        "1. Basic autograd example 1\n",
        "2. Basic autograd example 2\n",
        "3. Loading data from numpy\n",
        "4. Input pipeline\n",
        "5. Input pipleline from a custom dataset\n",
        "6. Pretrained model\n",
        "7. Save and load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S94zU1JnbcGG",
        "colab_type": "text"
      },
      "source": [
        "##Basic autograd example\n",
        "\n",
        "Pytorch Package for differentiation for operations on tensors.\n",
        "\n",
        "Basically computing gradients.\n",
        "\n",
        "A variable has a cost function, backward() executes and computes all backpropogation gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMzu17ehbGNJ",
        "colab_type": "code",
        "outputId": "62cee8d9-b565-46ab-baf5-5f8d981e310a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x= torch.tensor(1.,requires_grad=True)\n",
        "w=torch.tensor(2.,requires_grad=True)\n",
        "b=torch.tensor(3.,requires_grad=True)\n",
        "\n",
        "y=w*x+b\n",
        "y.backward()\n",
        "\n",
        "print(x.grad) #differentiation of y wrt x\n",
        "print(w.grad)  #differentiation of y wrt w\n",
        "print(b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOh_kT4qgVoH",
        "colab_type": "text"
      },
      "source": [
        "##Basic Autograd example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe6yjEmHgY7m",
        "colab_type": "code",
        "outputId": "7f7feae3-872c-4a7b-864c-589073602e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x=torch.randn(10,3) #10 datasamples of 3 attributes each\n",
        "y=torch.randn(10,2) #10 outputs to 10 datasamples\n",
        "\n",
        "linear=nn.Linear(3,2) #input=3 output=2\n",
        "print('w: ',linear.weight) \n",
        "print('b: ',linear.bias)\n",
        "\n",
        "criterion=nn.MSELoss() # Loss function  mean squared error ((input-target)**2).mean()\n",
        "optimizer=torch.optim.SGD(linear.parameters(),lr=0.01)\n",
        "\n",
        "pred=linear(x)\n",
        "\n",
        "loss=criterion(pred,y)\n",
        "print(\"loss: \",loss.item())\n",
        "\n",
        "#Backward Pass\n",
        "loss.backward()\n",
        "\n",
        "print(\"dL/dw: \",linear.weight.grad)\n",
        "print(\"dL/db: \",linear.bias.grad)\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "pred=linear(x)\n",
        "loss=criterion(pred,y)\n",
        "print('loss after 1 step of optimization: ', loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[0.2355, 0.3910, 0.0108],\n",
            "        [0.2024, 0.0393, 0.0765]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([-0.3630, -0.4766], requires_grad=True)\n",
            "loss:  0.7759305238723755\n",
            "dL/dw:  tensor([[ 0.0226,  0.6069, -0.0397],\n",
            "        [ 0.2056,  0.2710, -0.3016]])\n",
            "dL/db:  tensor([-0.3197, -0.5330])\n",
            "loss after 1 step of optimization:  0.7663639783859253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixYjpGsqiSnZ",
        "colab_type": "text"
      },
      "source": [
        "##Loading data from numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1DOfSK_iVmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.array([[1,2],[3,4]])\n",
        "\n",
        "y.torch.from_numpy(x)\n",
        "\n",
        "z=y.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LAyAmcPihK5",
        "colab_type": "text"
      },
      "source": [
        "##Input pipeline\n",
        "\n",
        "CIFAR Dataset 60000 images 32x32 size\n",
        "10 classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEo38a_oikSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset=torchvision.datasets.CIFAR10(root=\"./\",\n",
        "                                          train=True,\n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "image,label=train_dataset[0]\n",
        "print(image.size())\n",
        "print(label)\n",
        "\n",
        "#Data loader (provides queues and threads in a very simple way)\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                        batch_size=64,\n",
        "                                        shuffle=True)\n",
        "\n",
        "#When iteration starts, queue and thread start to load data from files\n",
        "data_iter=iter(train_loader)\n",
        "\n",
        "#Mini batch images and labels\n",
        "images,labels=data_iter.next()\n",
        "\n",
        "#Training one batch\n",
        "for images,labels in train_loader:\n",
        "   #Train code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mQpD2MnoVdZ",
        "colab_type": "text"
      },
      "source": [
        "##Input pipeline for custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMUrykPcoZyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    #TODO\n",
        "    # initializing file paths or list of file names\n",
        "  def __getitem__(self,index):\n",
        "    #1. Read one data from file (using numpy.fromfile, PIL.Image.open)\n",
        "    #2. Preprocess the data (torchvision.Transform)\n",
        "    #3. Return a data pair ( image,label)\n",
        "  def __len__(self):\n",
        "    #change 0 to total size of the dataset\n",
        "    return 0\n",
        "  \n",
        "custom_dataset=CustomDataset()\n",
        "train_loader=torch.utils.data.DataLoader(dataset=custom_dataset,\n",
        "                                        batch_size=64,\n",
        "                                        shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQdGfdClpjzQ",
        "colab_type": "text"
      },
      "source": [
        "##Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoEhtdWqplpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Download and load the pretrained ResNet-18\n",
        "resnet=torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# if your want to fineTune only the top layer of the model , set as below\n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad=False\n",
        "  \n",
        "#Replace the toplayer for finetuning\n",
        "resnet.fc=nn.Linear(resnet.fc.in_features,100) # 100 is an example\n",
        "images=torch.randn(64,3,224,224)\n",
        "output=resnet(images)\n",
        "print(output.size()) #64,100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-hW_VFrddO",
        "colab_type": "text"
      },
      "source": [
        "##Save and load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNU19ue6rczr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save and load the entire model\n",
        "torch.save(resnet,'model.ckpt')\n",
        "model=torch.load('model.ckpt')\n",
        "\n",
        "#Saving just the model parameters \n",
        "torch.save(resnet.state_dict(),'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF11FU6Hsa_Y",
        "colab_type": "text"
      },
      "source": [
        "#Pytorch Feed Forward Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMTE9QwmtJTg",
        "colab_type": "text"
      },
      "source": [
        "##Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghKfAFmSsiaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fgW_LLptEci",
        "colab_type": "text"
      },
      "source": [
        "##Declare the parameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC7l9SxessFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size=784\n",
        "hidden_size=500\n",
        "num_classes=10\n",
        "num_epochs=5\n",
        "batch_size=100\n",
        "learning_rate=0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NbRJYy7tL6P",
        "colab_type": "text"
      },
      "source": [
        "##Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N82BtblVtNq3",
        "colab_type": "code",
        "outputId": "6bae7951-d49d-4fdf-f803-e10c0c04c507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "train_dataset=torchvision.datasets.MNIST(root='./',\n",
        "                                        train=True,\n",
        "                                        transform=transforms.ToTensor(),\n",
        "                                        download=True)\n",
        "test_dataset=torchvision.datasets.MNIST(root=\"./\",\n",
        "                                       train=False,\n",
        "                                       transform=transforms.ToTensor())\n",
        "\n",
        "#DataLoader\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True)\n",
        "\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27754101.73it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 440445.94it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 144260.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7506329.10it/s]                            \n",
            "8192it [00:00, 171495.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jle3XE-OyCMd",
        "colab_type": "code",
        "outputId": "38968e92-e375-40a3-8494-a4d7c8e3f054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images,label=train_dataset[0]\n",
        "label"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59AKrSQkujQH",
        "colab_type": "text"
      },
      "source": [
        "##Model Creation\n",
        "\n",
        "1.Define the layer input and output in init\n",
        "Add activation functions after each layer\n",
        "\n",
        "2. Define forward function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSd7CNvwum24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.fc1= nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.fc2=nn.Linear(hidden_size,num_classes)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out=self.fc1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jgoRQqevjL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=NeuralNet(input_size,hidden_size, num_classes).to(device)\n",
        "\n",
        "#Loss and optimizer\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0YLReV7t5zo",
        "colab_type": "text"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQstIXRxt7qt",
        "colab_type": "code",
        "outputId": "a13cc8ef-180a-441a-8237-10cdd3ddc40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "total_step=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    images=images.reshape(-1,28*28).to(device) ##Flattens 28*28 image for 784 input\n",
        "    labels=labels.to(device)\n",
        "    \n",
        "    #forward pass\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if(i+1)%100==0:\n",
        "      print('Epoch [{}/{}], Step[{}/{}],Loss:{:.4f}'\n",
        "           .format(epoch+1,num_epochs,i+1,total_step,loss.item()))\n",
        "      \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step[100/600],Loss:0.4004\n",
            "Epoch [1/5], Step[200/600],Loss:0.1431\n",
            "Epoch [1/5], Step[300/600],Loss:0.3492\n",
            "Epoch [1/5], Step[400/600],Loss:0.1435\n",
            "Epoch [1/5], Step[500/600],Loss:0.1150\n",
            "Epoch [1/5], Step[600/600],Loss:0.1582\n",
            "Epoch [2/5], Step[100/600],Loss:0.0926\n",
            "Epoch [2/5], Step[200/600],Loss:0.0420\n",
            "Epoch [2/5], Step[300/600],Loss:0.1494\n",
            "Epoch [2/5], Step[400/600],Loss:0.1191\n",
            "Epoch [2/5], Step[500/600],Loss:0.1079\n",
            "Epoch [2/5], Step[600/600],Loss:0.0574\n",
            "Epoch [3/5], Step[100/600],Loss:0.1086\n",
            "Epoch [3/5], Step[200/600],Loss:0.0886\n",
            "Epoch [3/5], Step[300/600],Loss:0.0654\n",
            "Epoch [3/5], Step[400/600],Loss:0.1828\n",
            "Epoch [3/5], Step[500/600],Loss:0.0212\n",
            "Epoch [3/5], Step[600/600],Loss:0.0699\n",
            "Epoch [4/5], Step[100/600],Loss:0.0405\n",
            "Epoch [4/5], Step[200/600],Loss:0.0477\n",
            "Epoch [4/5], Step[300/600],Loss:0.0601\n",
            "Epoch [4/5], Step[400/600],Loss:0.0116\n",
            "Epoch [4/5], Step[500/600],Loss:0.0873\n",
            "Epoch [4/5], Step[600/600],Loss:0.0220\n",
            "Epoch [5/5], Step[100/600],Loss:0.0476\n",
            "Epoch [5/5], Step[200/600],Loss:0.0409\n",
            "Epoch [5/5], Step[300/600],Loss:0.0849\n",
            "Epoch [5/5], Step[400/600],Loss:0.0180\n",
            "Epoch [5/5], Step[500/600],Loss:0.0124\n",
            "Epoch [5/5], Step[600/600],Loss:0.0809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvzcM-9I0_NQ",
        "colab_type": "text"
      },
      "source": [
        "##Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_KiimPX0xvU",
        "colab_type": "code",
        "outputId": "7b6b1537-53c0-4700-8625-96c044d0b47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  total=0\n",
        "  for images,labels in test_loader:\n",
        "    images=images.reshape(-1,28*28).to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs=model(images)\n",
        "    _,predicted=torch.max(outputs.data,1)\n",
        "    total+=labels.size(0)\n",
        "    correct+=(predicted==labels).sum().item()\n",
        "    \n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "torch.save(model.state_dict(),'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.73 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}